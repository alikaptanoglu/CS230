{\rtf1\ansi\ansicpg936\cocoartf2513
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red25\green25\blue25;\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c12941\c12941\c12941;\cssrgb\c100000\c100000\c100000;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 ensemble_embedding Parameter sets: [200, 200, 0.001, 0.5, 1, 0.5, 30, 100, 130, 200]\
## Building an RNN model\
Tensor("Unigram/Unigram/embedding_lookup:0", shape=(?, 50, 30), dtype=float32)\
Tensor("Bigram/Bigram/embedding_lookup:0", shape=(?, 50, 100), dtype=float32)\
Tensor("Trigram/Trigram/embedding_lookup:0", shape=(?, 50, 130), dtype=float32)\
Tensor("Fourgram/Fourgram/embedding_lookup:0", shape=(?, 50, 200), dtype=float32)\
/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "\
model variables ['Unigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/weights:0', 'Unigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/biases:0', 'Unigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/weights:0', 'Unigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/biases:0', 'Unigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_w:0', 'Unigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_v:0', 'Unigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/weights:0', 'Unigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/biases:0', 'Unigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/weights:0', 'Unigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/biases:0', 'Bigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/weights:0', 'Bigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/biases:0', 'Bigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/weights:0', 'Bigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/biases:0', 'Bigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_w:0', 'Bigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_v:0', 'Bigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/weights:0', 'Bigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/biases:0', 'Bigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/weights:0', 'Bigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/biases:0', 'Trigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/weights:0', 'Trigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/biases:0', 'Trigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/weights:0', 'Trigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/biases:0', 'Trigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_w:0', 'Trigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_v:0', 'Trigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/weights:0', 'Trigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/biases:0', 'Trigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/weights:0', 'Trigram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/biases:0', 'Fourgram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/weights:0', 'Fourgram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/biases:0', 'Fourgram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/weights:0', 'Fourgram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/basic_lstm_cell/biases:0', 'Fourgram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_w:0', 'Fourgram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/attn_v:0', 'Fourgram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/weights:0', 'Fourgram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/attention/biases:0', 'Fourgram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/weights:0', 'Fourgram/RNN/multi_rnn_cell/cell_0/attention_cell_wrapper/attn_output_projection/biases:0', 'Hidden1/Weights:0', 'Hidden1/Biases:0', 'Output/Weights:0', 'Output/Biases:0']\
## Training\
Percent: [####################] 100.00% Finished. tr loss: 14.049, acc1: 0.242, acc5: 0.596\
Training loss: 32.085, acc1: 0.178, acc5: 0.501, ep: 0\
\
Validation loss: 2.888, acc1: 0.420, acc5: 0.758, ep: 0\
Testing loss: 2.867, acc1: 0.415, acc5: 0.756\
\
Model saved ensemble_embedding.model\
Process time per epoch: 1174.835 seconds\
\
Percent: [####################] 100.00% Finished. tr loss: 8.341, acc1: 0.237, acc5: 0.579\
Training loss: 9.967, acc1: 0.254, acc5: 0.596, ep: 1\
\
Validation loss: 1.930, acc1: 0.420, acc5: 0.761, ep: 1\
Testing loss: 1.901, acc1: 0.433, acc5: 0.759\
\
Model saved ensemble_embedding.model\
Process time per epoch: 1148.862 seconds\
\
Percent: [####################] 100.00% Finished. tr loss: 5.763, acc1: 0.312, acc5: 0.629\
Training loss: 6.533, acc1: 0.285, acc5: 0.616, ep: 2\
\
Validation loss: 2.000, acc1: 0.397, acc5: 0.709, ep: 2\
Testing loss: 2.016, acc1: 0.398, acc5: 0.720\
\
Model saved ensemble_embedding.model\
Process time per epoch: 1147.864 seconds\
\
Percent: [####################] 100.00% Finished. tr loss: 3.885, acc1: 0.321, acc5: 0.654\
Training loss: 4.634, acc1: 0.290, acc5: 0.623, ep: 3\
\
Validation loss: 2.061, acc1: 0.387, acc5: 0.721, ep: 3\
Testing loss: 2.068, acc1: 0.403, acc5: 0.729\
\
Model saved ensemble_embedding.model\
Process time per epoch: 1125.542 seconds\
\
Percent: [####################] 100.00% Finished. tr loss: 3.358, acc1: 0.325, acc5: 0.646\
Training loss: 3.784, acc1: 0.300, acc5: 0.629, ep: 4\
\
Validation loss: 2.050, acc1: 0.423, acc5: 0.722, ep: 4\
Testing loss: 2.043, acc1: 0.424, acc5: 0.732\
\
Model saved ensemble_embedding.model\
Process time per epoch: 1076.898 seconds\
\
Percent: [####################] 100.00% Finished. tr loss: 2.843, acc1: 0.333, acc5: 0.704\
Training loss: 3.209, acc1: 0.324, acc5: 0.658, ep: 5\
\
Validation loss: 2.023, acc1: 0.428, acc5: 0.736, ep: 5\
Testing loss: 2.014, acc1: 0.444, acc5: 0.753\
\
Model saved ensemble_embedding.model\
Process time per epoch: 1066.652 seconds\
\
Percent: [####################] 100.00% Finished. tr loss: 2.500, acc1: 0.375, acc5: 0.708\
Training loss: 2.891, acc1: 0.350, acc5: 0.672, ep: 6\
\
Validation loss: 1.863, acc1: 0.488, acc5: 0.790, ep: 6\
Testing loss: 1.847, acc1: 0.494, acc5: 0.800\
\
Model saved ensemble_embedding.model\
Process time per epoch: 1059.552 seconds\
\
Percent: [####################] 100.00% Finished. tr loss: 2.361, acc1: 0.408, acc5: 0.708\
Training loss: 2.627, acc1: 0.379, acc5: 0.692, ep: 7\
\
Validation loss: 1.823, acc1: 0.489, acc5: 0.807, ep: 7\
Testing loss: 1.805, acc1: 0.499, acc5: 0.821\
\
Model saved ensemble_embedding.model\
Process time per epoch: 1065.440 seconds\
\
Percent: [####################] 100.00% Finished. tr loss: 2.337, acc1: 0.375, acc5: 0.708\
Training loss: 2.533, acc1: 0.380, acc5: 0.701, ep: 8\
\
Validation loss: 1.812, acc1: 0.505, acc5: 0.819, ep: 8\
Testing loss: 1.797, acc1: 0.503, acc5: 0.813\
\
Model saved ensemble_embedding.model\
Process time per epoch: 1054.011 seconds\
\
Percent: [####################] 100.00% Finished. tr loss: 2.162, acc1: 0.392, acc5: 0.725\
Training loss: 2.403, acc1: 0.387, acc5: 0.709, ep: 9\
\
Validation loss: 1.698, acc1: 0.532, acc5: 0.847, ep: 9\
Testing loss: 1.694, acc1: 0.539, acc5: 0.838\
\
Model saved ensemble_embedding.model\
Process time per epoch: 1061.931 seconds\
\
Percent: [####################] 100.00% Finished. tr loss: 2.089, acc1: 0.433, acc5: 0.754\
Training loss: 2.295, acc1: 0.415, acc5: 0.733, ep: 10\
\
Validation loss: 1.616, acc1: 0.577, acc5: 0.858, ep: 10\
Testing loss: 1.610, acc1: 0.562, acc5: 0.854\
\
Model saved ensemble_embedding.model\
Process time per epoch: 1055.498 seconds\
\
Percent: [####################] 100.00% Finished. tr loss: 2.225, acc1: 0.404, acc5: 0.733\
Training loss: 2.247, acc1: 0.428, acc5: 0.740, ep: 11\
\
Validation loss: 1.642, acc1: 0.551, acc5: 0.852, ep: 11\
Testing loss: 1.623, acc1: 0.558, acc5: 0.863\
\
Model saved ensemble_embedding.model\
Process time per epoch: 1066.621 seconds\
\
Percent: [####################] 100.00% Finished. tr loss: 1.996, acc1: 0.475, acc5: 0.758\
Training loss: 2.202, acc1: 0.432, acc5: 0.751, ep: 12\
\
Validation loss: 1.557, acc1: 0.568, acc5: 0.870, ep: 12\
Testing loss: 1.539, acc1: 0.578, acc5: 0.880\
\
Model saved ensemble_embedding.model\
Process time per epoch: 1059.449 seconds\
\
Percent: [####################] 100.00% Finished. tr loss: 1.856, acc1: 0.475, acc5: 0.812\
Training loss: 2.093, acc1: 0.448, acc5: 0.768, ep: 13\
\
Validation loss: 1.460, acc1: 0.583, acc5: 0.882, ep: 13\
Testing loss: 1.446, acc1: 0.609, acc5: 0.887\
\
Model saved ensemble_embedding.model\
Process time per epoch: 1077.554 seconds\
\
Percent: [###########         ] 53.41%  tr loss: 2.100, acc1: 0.438, acc5: 0.768}