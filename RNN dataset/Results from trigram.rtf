{\rtf1\ansi\ansicpg936\cocoartf2512
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red25\green25\blue25;\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c12941\c12941\c12941;\cssrgb\c100000\c100000\c100000;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 \{'batch_size': 300,\
 'checkpoint_dir': './checkpoint/trigram_embedding',\
 'continue_train': False,\
 'data_dir': './data/raw',\
 'decay_rate': 0.99,\
 'decay_step': 100,\
 'default_params': True,\
 'detail_result_path': '/content/CS230/result/detail.txt',\
 'dim_bigram': 1876,\
 'dim_embed_bigram': 100,\
 'dim_embed_bigram_max': 200,\
 'dim_embed_bigram_min': 30,\
 'dim_embed_trigram': 130,\
 'dim_embed_trigram_max': 320,\
 'dim_embed_trigram_min': 30,\
 'dim_embed_unigram': 30,\
 'dim_embed_unigram_max': 100,\
 'dim_embed_unigram_min': 10,\
 'dim_hidden': 200,\
 'dim_hidden_max': 399,\
 'dim_hidden_min': 200,\
 'dim_output': 127,\
 'dim_rnn_cell': 200,\
 'dim_rnn_cell_max': 399,\
 'dim_rnn_cell_min': 200,\
 'dim_trigram': 14767,\
 'dim_unigram': 82,\
 'embed': True,\
 'embed_trainable': False,\
 'ensemble': False,\
 'ethnicity': False,\
 'hidden_dropout': 0.5,\
 'hidden_dropout_max': 0.8,\
 'hidden_dropout_min': 0.3,\
 'is_train': True,\
 'is_valid': True,\
 'learning_rate': 0.01,\
 'learning_rate_max': 0.05,\
 'learning_rate_min': 0.005,\
 'lstm_dropout': 0.5,\
 'lstm_dropout_max': 0.8,\
 'lstm_dropout_min': 0.3,\
 'lstm_layer': 1,\
 'lstm_layer_max': 1,\
 'lstm_layer_min': 1,\
 'max_grad': 5,\
 'max_time_step': 60,\
 'min_grad': -5,\
 'model_name': 'trigram_embedding',\
 'ngram': 3,\
 'pred_result_path': '/content/CS230/result/pred.txt',\
 'save': False,\
 'train_epoch': 3000,\
 'valid_iteration': 250,\
 'valid_result_path': '/content/CS230/result/validation'\}\
reading 0_unigram_to_idx.txt of length 82\
reading 1_bigram_to_idx.txt of length 1876\
reading 2_trigram_to_idx.txt of length 14767\
reading country_to_ethnicity.txt of length 127\
reading country_to_idx.txt of length 127\
reading data_ijcai_authors of length 2408\
reading data_raw_test of length 3543\
reading data_raw_train of length 10633\
reading data_raw_train_ch of length 10754\
reading data_raw_valid of length 3545\
total data length: 10754 3545 2408\
shape of data: (5, 10754) (5, 3545) (5, 2408)\
name max length: 47\
[8, 45, 38, 57, 0, 14, 16, 22, 25, 14, 12, 27, 27, 16]\
[168, 1436, 1289, 1718, 11, 404, 497, 761, 841, 400, 325, 944, 934]\
[1626, 12101, 10973, 14236, 206, 3538, 4369, 6709, 7324, 3494, 3030, 8385]\
14 46\
shape of data: (5, 10754) (5, 3545) (5, 2408)\
preprocessing done\
\
trigram_embedding Parameter sets: [200, 200, 0.01, 0.5, 1, 0.5, 30, 100, 130]\
## Building an RNN model\
Tensor("Unigram/Unigram/embedding_lookup:0", shape=(?, 60, 30), dtype=float32)\
Tensor("Bigram/Bigram/embedding_lookup:0", shape=(?, 60, 100), dtype=float32)\
Tensor("Trigram/Trigram/embedding_lookup:0", shape=(?, 60, 130), dtype=float32)\
/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "\
model variables ['Unigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0', 'Unigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0', 'Bigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0', 'Bigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0', 'Trigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0', 'Trigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0', 'Hidden1/Weights:0', 'Hidden1/Biases:0', 'Output/Weights:0', 'Output/Biases:0']\
## Training\
Percent: [####################] 100.00% Finished. tr loss: 7.875, acc1: 0.083, acc5: 0.224\
Training loss: 4.815, acc1: 0.110, acc5: 0.284, ep: 0\
\
Validation loss: 3.378, acc1: 0.189, acc5: 0.484, ep: 0\
Testing loss: 6.196, acc1: 0.000, acc5: 0.149\
\
Percent: [####################] 100.00% Finished. tr loss: 2.942, acc1: 0.252, acc5: 0.602\
Training loss: 3.446, acc1: 0.174, acc5: 0.468, ep: 1\
\
Validation loss: 3.109, acc1: 0.237, acc5: 0.535, ep: 1\
Testing loss: 6.589, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 2.452, acc1: 0.335, acc5: 0.693\
Training loss: 3.152, acc1: 0.222, acc5: 0.529, ep: 2\
\
Validation loss: 3.006, acc1: 0.261, acc5: 0.555, ep: 2\
Testing loss: 10.639, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.706, acc1: 0.571, acc5: 0.764\
Training loss: 2.922, acc1: 0.281, acc5: 0.564, ep: 3\
\
Validation loss: 2.872, acc1: 0.288, acc5: 0.588, ep: 3\
Testing loss: 11.058, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.603, acc1: 0.583, acc5: 0.748\
Training loss: 2.778, acc1: 0.308, acc5: 0.596, ep: 4\
\
Validation loss: 2.776, acc1: 0.293, acc5: 0.599, ep: 4\
Testing loss: 11.674, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.563, acc1: 0.602, acc5: 0.787\
Training loss: 2.693, acc1: 0.329, acc5: 0.610, ep: 5\
\
Validation loss: 2.717, acc1: 0.306, acc5: 0.616, ep: 5\
Testing loss: 11.821, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.546, acc1: 0.622, acc5: 0.783\
Training loss: 2.661, acc1: 0.329, acc5: 0.623, ep: 6\
\
Validation loss: 2.652, acc1: 0.320, acc5: 0.623, ep: 6\
Testing loss: 12.571, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.486, acc1: 0.618, acc5: 0.783\
Training loss: 2.551, acc1: 0.354, acc5: 0.640, ep: 7\
\
Validation loss: 2.585, acc1: 0.328, acc5: 0.659, ep: 7\
Testing loss: 12.718, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.415, acc1: 0.618, acc5: 0.803\
Training loss: 2.492, acc1: 0.366, acc5: 0.660, ep: 8\
\
Validation loss: 2.546, acc1: 0.333, acc5: 0.673, ep: 8\
Testing loss: 13.444, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.416, acc1: 0.646, acc5: 0.811\
Training loss: 2.436, acc1: 0.379, acc5: 0.667, ep: 9\
\
Validation loss: 2.511, acc1: 0.346, acc5: 0.661, ep: 9\
Testing loss: 13.053, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.412, acc1: 0.606, acc5: 0.807\
Training loss: 2.400, acc1: 0.390, acc5: 0.678, ep: 10\
\
Validation loss: 2.506, acc1: 0.348, acc5: 0.674, ep: 10\
Testing loss: 13.586, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.309, acc1: 0.646, acc5: 0.835\
Training loss: 2.330, acc1: 0.407, acc5: 0.695, ep: 11\
\
Validation loss: 2.476, acc1: 0.360, acc5: 0.691, ep: 11\
Testing loss: 13.252, acc1: 0.000, acc5: 0.002\
\
Percent: [####################] 100.00% Finished. tr loss: 1.337, acc1: 0.638, acc5: 0.835\
Training loss: 2.231, acc1: 0.417, acc5: 0.715, ep: 12\
\
Validation loss: 2.412, acc1: 0.373, acc5: 0.700, ep: 12\
Testing loss: 15.448, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.242, acc1: 0.685, acc5: 0.831\
Training loss: 2.187, acc1: 0.434, acc5: 0.732, ep: 13\
\
Validation loss: 2.434, acc1: 0.372, acc5: 0.698, ep: 13\
Testing loss: 15.447, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 1.298, acc1: 0.665, acc5: 0.839\
Training loss: 2.186, acc1: 0.430, acc5: 0.722, ep: 14\
\
Validation loss: 2.418, acc1: 0.383, acc5: 0.712, ep: 14\
Testing loss: 15.656, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.298, acc1: 0.657, acc5: 0.827\
Training loss: 2.136, acc1: 0.441, acc5: 0.734, ep: 15\
\
Validation loss: 2.427, acc1: 0.385, acc5: 0.699, ep: 15\
Testing loss: 15.305, acc1: 0.001, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 1.330, acc1: 0.657, acc5: 0.819\
Training loss: 2.107, acc1: 0.441, acc5: 0.737, ep: 16\
\
Validation loss: 2.413, acc1: 0.374, acc5: 0.696, ep: 16\
Testing loss: 14.240, acc1: 0.001, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 1.236, acc1: 0.650, acc5: 0.819\
Training loss: 2.046, acc1: 0.439, acc5: 0.750, ep: 17\
\
Validation loss: 2.434, acc1: 0.381, acc5: 0.704, ep: 17\
Testing loss: 14.118, acc1: 0.000, acc5: 0.002\
\
Percent: [####################] 100.00% Finished. tr loss: 1.121, acc1: 0.685, acc5: 0.862\
Training loss: 1.978, acc1: 0.472, acc5: 0.767, ep: 18\
\
Validation loss: 2.436, acc1: 0.388, acc5: 0.703, ep: 18\
Testing loss: 15.125, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.172, acc1: 0.661, acc5: 0.858\
Training loss: 1.944, acc1: 0.475, acc5: 0.771, ep: 19\
\
Validation loss: 2.392, acc1: 0.390, acc5: 0.704, ep: 19\
Testing loss: 15.664, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.201, acc1: 0.673, acc5: 0.866\
Training loss: 1.916, acc1: 0.477, acc5: 0.778, ep: 20\
\
Validation loss: 2.398, acc1: 0.404, acc5: 0.704, ep: 20\
Testing loss: 15.691, acc1: 0.001, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 1.116, acc1: 0.713, acc5: 0.882\
Training loss: 1.834, acc1: 0.505, acc5: 0.801, ep: 21\
\
Validation loss: 2.458, acc1: 0.376, acc5: 0.695, ep: 21\
Testing loss: 15.187, acc1: 0.001, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 1.126, acc1: 0.713, acc5: 0.870\
Training loss: 1.817, acc1: 0.508, acc5: 0.797, ep: 22\
\
Validation loss: 2.451, acc1: 0.389, acc5: 0.695, ep: 22\
Testing loss: 15.499, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.062, acc1: 0.705, acc5: 0.894\
Training loss: 1.739, acc1: 0.505, acc5: 0.816, ep: 23\
\
Validation loss: 2.437, acc1: 0.400, acc5: 0.703, ep: 23\
Testing loss: 15.545, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 0.982, acc1: 0.705, acc5: 0.890\
Training loss: 1.704, acc1: 0.521, acc5: 0.819, ep: 24\
\
Validation loss: 2.464, acc1: 0.395, acc5: 0.696, ep: 24\
Testing loss: 15.878, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.030, acc1: 0.720, acc5: 0.878\
Training loss: 1.697, acc1: 0.528, acc5: 0.823, ep: 25\
\
Validation loss: 2.548, acc1: 0.387, acc5: 0.696, ep: 25\
Testing loss: 16.009, acc1: 0.000, acc5: 0.001\
\
Early stopping applied\
\
Testing loss: 16.009, acc1: 0.000, acc5: 0.001\
trigram_embedding Parameter sets: [200, 200, 0.01, 0.5, 1, 0.5, 30, 100, 130]\
## Building an RNN model\
Tensor("Unigram/Unigram/embedding_lookup:0", shape=(?, 60, 30), dtype=float32)\
Tensor("Bigram/Bigram/embedding_lookup:0", shape=(?, 60, 100), dtype=float32)\
Tensor("Trigram/Trigram/embedding_lookup:0", shape=(?, 60, 130), dtype=float32)\
model variables ['Unigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0', 'Unigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0', 'Bigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0', 'Bigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0', 'Trigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0', 'Trigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0', 'Hidden1/Weights:0', 'Hidden1/Biases:0', 'Output/Weights:0', 'Output/Biases:0']\
## Training\
Percent: [####################] 100.00% Finished. tr loss: 5.161, acc1: 0.063, acc5: 0.197\
Training loss: 4.664, acc1: 0.099, acc5: 0.249, ep: 0\
\
Validation loss: 3.498, acc1: 0.158, acc5: 0.437, ep: 0\
Testing loss: 6.186, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 3.037, acc1: 0.244, acc5: 0.496\
Training loss: 3.523, acc1: 0.168, acc5: 0.424, ep: 1\
\
Validation loss: 3.227, acc1: 0.196, acc5: 0.517, ep: 1\
Testing loss: 7.160, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 2.500, acc1: 0.362, acc5: 0.657\
Training loss: 3.235, acc1: 0.220, acc5: 0.506, ep: 2\
\
Validation loss: 3.062, acc1: 0.248, acc5: 0.546, ep: 2\
Testing loss: 7.149, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 2.031, acc1: 0.472, acc5: 0.728\
Training loss: 3.004, acc1: 0.247, acc5: 0.550, ep: 3\
\
Validation loss: 2.966, acc1: 0.259, acc5: 0.557, ep: 3\
Testing loss: 7.746, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.997, acc1: 0.516, acc5: 0.744\
Training loss: 2.888, acc1: 0.293, acc5: 0.577, ep: 4\
\
Validation loss: 2.847, acc1: 0.282, acc5: 0.586, ep: 4\
Testing loss: 8.125, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.779, acc1: 0.543, acc5: 0.736\
Training loss: 2.742, acc1: 0.317, acc5: 0.600, ep: 5\
\
Validation loss: 2.790, acc1: 0.299, acc5: 0.610, ep: 5\
Testing loss: 7.618, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 1.652, acc1: 0.571, acc5: 0.795\
Training loss: 2.665, acc1: 0.325, acc5: 0.622, ep: 6\
\
Validation loss: 2.723, acc1: 0.316, acc5: 0.611, ep: 6\
Testing loss: 8.587, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 1.591, acc1: 0.594, acc5: 0.787\
Training loss: 2.565, acc1: 0.347, acc5: 0.646, ep: 7\
\
Validation loss: 2.651, acc1: 0.329, acc5: 0.630, ep: 7\
Testing loss: 7.941, acc1: 0.000, acc5: 0.046\
\
Percent: [####################] 100.00% Finished. tr loss: 1.565, acc1: 0.602, acc5: 0.795\
Training loss: 2.515, acc1: 0.356, acc5: 0.661, ep: 8\
\
Validation loss: 2.598, acc1: 0.346, acc5: 0.630, ep: 8\
Testing loss: 8.711, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 1.490, acc1: 0.630, acc5: 0.799\
Training loss: 2.442, acc1: 0.379, acc5: 0.677, ep: 9\
\
Validation loss: 2.585, acc1: 0.340, acc5: 0.649, ep: 9\
Testing loss: 8.906, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 1.468, acc1: 0.626, acc5: 0.811\
Training loss: 2.399, acc1: 0.387, acc5: 0.688, ep: 10\
\
Validation loss: 2.549, acc1: 0.352, acc5: 0.659, ep: 10\
Testing loss: 9.313, acc1: 0.000, acc5: 0.003\
\
Percent: [####################] 100.00% Finished. tr loss: 1.465, acc1: 0.630, acc5: 0.835\
Training loss: 2.354, acc1: 0.385, acc5: 0.698, ep: 11\
\
Validation loss: 2.477, acc1: 0.364, acc5: 0.671, ep: 11\
Testing loss: 9.743, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.421, acc1: 0.630, acc5: 0.819\
Training loss: 2.250, acc1: 0.411, acc5: 0.719, ep: 12\
\
Validation loss: 2.467, acc1: 0.377, acc5: 0.674, ep: 12\
Testing loss: 9.936, acc1: 0.000, acc5: 0.002\
\
Percent: [####################] 100.00% Finished. tr loss: 1.354, acc1: 0.634, acc5: 0.843\
Training loss: 2.202, acc1: 0.413, acc5: 0.723, ep: 13\
\
Validation loss: 2.454, acc1: 0.372, acc5: 0.685, ep: 13\
Testing loss: 10.298, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.322, acc1: 0.661, acc5: 0.846\
Training loss: 2.154, acc1: 0.434, acc5: 0.741, ep: 14\
\
Validation loss: 2.432, acc1: 0.373, acc5: 0.685, ep: 14\
Testing loss: 10.066, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.337, acc1: 0.642, acc5: 0.839\
Training loss: 2.118, acc1: 0.427, acc5: 0.738, ep: 15\
\
Validation loss: 2.452, acc1: 0.384, acc5: 0.675, ep: 15\
Testing loss: 10.983, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.171, acc1: 0.701, acc5: 0.850\
Training loss: 2.056, acc1: 0.461, acc5: 0.741, ep: 16\
\
Validation loss: 2.379, acc1: 0.396, acc5: 0.698, ep: 16\
Testing loss: 11.825, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.246, acc1: 0.661, acc5: 0.850\
Training loss: 1.992, acc1: 0.462, acc5: 0.768, ep: 17\
\
Validation loss: 2.392, acc1: 0.385, acc5: 0.696, ep: 17\
Testing loss: 11.265, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 1.144, acc1: 0.685, acc5: 0.862\
Training loss: 1.947, acc1: 0.481, acc5: 0.767, ep: 18\
\
Validation loss: 2.387, acc1: 0.402, acc5: 0.697, ep: 18\
Testing loss: 11.263, acc1: 0.000, acc5: 0.002\
\
Percent: [####################] 100.00% Finished. tr loss: 1.093, acc1: 0.713, acc5: 0.882\
Training loss: 1.853, acc1: 0.499, acc5: 0.792, ep: 19\
\
Validation loss: 2.439, acc1: 0.388, acc5: 0.705, ep: 19\
Testing loss: 12.081, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.090, acc1: 0.705, acc5: 0.878\
Training loss: 1.817, acc1: 0.497, acc5: 0.798, ep: 20\
\
Validation loss: 2.391, acc1: 0.401, acc5: 0.720, ep: 20\
Testing loss: 12.923, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.097, acc1: 0.677, acc5: 0.882\
Training loss: 1.772, acc1: 0.511, acc5: 0.809, ep: 21\
\
Validation loss: 2.417, acc1: 0.397, acc5: 0.706, ep: 21\
Testing loss: 12.655, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.066, acc1: 0.669, acc5: 0.890\
Training loss: 1.735, acc1: 0.503, acc5: 0.817, ep: 22\
\
Validation loss: 2.434, acc1: 0.395, acc5: 0.718, ep: 22\
Testing loss: 12.707, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.048, acc1: 0.693, acc5: 0.894\
Training loss: 1.704, acc1: 0.519, acc5: 0.820, ep: 23\
\
Validation loss: 2.499, acc1: 0.389, acc5: 0.709, ep: 23\
Testing loss: 12.615, acc1: 0.000, acc5: 0.001\
\
Early stopping applied\
\
Testing loss: 12.615, acc1: 0.000, acc5: 0.001\
trigram_embedding Parameter sets: [200, 200, 0.01, 0.5, 1, 0.5, 30, 100, 130]\
## Building an RNN model\
Tensor("Unigram/Unigram/embedding_lookup:0", shape=(?, 60, 30), dtype=float32)\
Tensor("Bigram/Bigram/embedding_lookup:0", shape=(?, 60, 100), dtype=float32)\
Tensor("Trigram/Trigram/embedding_lookup:0", shape=(?, 60, 130), dtype=float32)\
model variables ['Unigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0', 'Unigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0', 'Bigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0', 'Bigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0', 'Trigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0', 'Trigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0', 'Hidden1/Weights:0', 'Hidden1/Biases:0', 'Output/Weights:0', 'Output/Biases:0']\
## Training\
Percent: [###                 ] 16.74%  tr loss: 5.520, acc1: 0.083, acc5: 0.243}