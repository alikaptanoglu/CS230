{\rtf1\ansi\ansicpg936\cocoartf2512
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red25\green25\blue25;\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c12941\c12941\c12941;\cssrgb\c100000\c100000\c100000;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 \{'batch_size': 300,\
 'checkpoint_dir': './checkpoint/ensemble_embedding',\
 'continue_train': False,\
 'data_dir': './data/raw',\
 'decay_rate': 0.99,\
 'decay_step': 100,\
 'default_params': True,\
 'detail_result_path': '/content/ethnicity-tensorflow/result/detail.txt',\
 'dim_bigram': 1876,\
 'dim_embed_bigram': 100,\
 'dim_embed_bigram_max': 200,\
 'dim_embed_bigram_min': 30,\
 'dim_embed_trigram': 130,\
 'dim_embed_trigram_max': 320,\
 'dim_embed_trigram_min': 30,\
 'dim_embed_unigram': 30,\
 'dim_embed_unigram_max': 100,\
 'dim_embed_unigram_min': 10,\
 'dim_hidden': 200,\
 'dim_hidden_max': 399,\
 'dim_hidden_min': 200,\
 'dim_output': 127,\
 'dim_rnn_cell': 200,\
 'dim_rnn_cell_max': 399,\
 'dim_rnn_cell_min': 200,\
 'dim_trigram': 14767,\
 'dim_unigram': 82,\
 'embed': True,\
 'embed_trainable': False,\
 'ensemble': True,\
 'ethnicity': False,\
 'hidden_dropout': 0.5,\
 'hidden_dropout_max': 0.8,\
 'hidden_dropout_min': 0.3,\
 'is_train': True,\
 'is_valid': True,\
 'learning_rate': 0.01,\
 'learning_rate_max': 0.05,\
 'learning_rate_min': 0.005,\
 'lstm_dropout': 0.5,\
 'lstm_dropout_max': 0.8,\
 'lstm_dropout_min': 0.3,\
 'lstm_layer': 1,\
 'lstm_layer_max': 1,\
 'lstm_layer_min': 1,\
 'max_grad': 5,\
 'max_time_step': 60,\
 'min_grad': -5,\
 'model_name': 'ensemble_embedding',\
 'ngram': 3,\
 'pred_result_path': '/content/ethnicity-tensorflow/result/pred.txt',\
 'save': False,\
 'train_epoch': 3000,\
 'valid_iteration': 250,\
 'valid_result_path': '/content/ethnicity-tensorflow/result/validation'\}\
reading 0_unigram_to_idx.txt of length 82\
reading 1_bigram_to_idx.txt of length 1876\
reading 2_trigram_to_idx.txt of length 14767\
reading country_to_ethnicity.txt of length 127\
reading country_to_idx.txt of length 127\
reading data_ijcai_authors of length 2408\
reading data_raw_test of length 3543\
reading data_raw_train of length 10633\
reading data_raw_train_ch of length 10754\
reading data_raw_valid of length 3545\
total data length: 10754 3545 2408\
shape of data: (5, 10754) (5, 3545) (5, 2408)\
name max length: 47\
[8, 45, 38, 57, 0, 14, 16, 22, 25, 14, 12, 27, 27, 16]\
[168, 1436, 1289, 1718, 11, 404, 497, 761, 841, 400, 325, 944, 934]\
[1626, 12101, 10973, 14236, 206, 3538, 4369, 6709, 7324, 3494, 3030, 8385]\
14 46\
shape of data: (5, 10754) (5, 3545) (5, 2408)\
preprocessing done\
\
ensemble_embedding Parameter sets: [200, 200, 0.01, 0.5, 1, 0.5, 30, 100, 130]\
## Building an RNN model\
Tensor("Unigram/Unigram/embedding_lookup:0", shape=(?, 60, 30), dtype=float32)\
Tensor("Bigram/Bigram/embedding_lookup:0", shape=(?, 60, 100), dtype=float32)\
Tensor("Trigram/Trigram/embedding_lookup:0", shape=(?, 60, 130), dtype=float32)\
/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "\
model variables ['Unigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0', 'Unigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0', 'Bigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0', 'Bigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0', 'Trigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0', 'Trigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0', 'Hidden1/Weights:0', 'Hidden1/Biases:0', 'Output/Weights:0', 'Output/Biases:0']\
## Training\
Percent: [####################] 100.00% Finished. tr loss: 23.858, acc1: 0.122, acc5: 0.315\
Training loss: 7.895, acc1: 0.195, acc5: 0.385, ep: 0\
\
Validation loss: 2.740, acc1: 0.342, acc5: 0.641, ep: 0\
Testing loss: 19.945, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.506, acc1: 0.618, acc5: 0.803\
Training loss: 2.768, acc1: 0.346, acc5: 0.628, ep: 1\
\
Validation loss: 2.536, acc1: 0.383, acc5: 0.682, ep: 1\
Testing loss: 34.380, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.392, acc1: 0.634, acc5: 0.850\
Training loss: 2.486, acc1: 0.390, acc5: 0.684, ep: 2\
\
Validation loss: 2.379, acc1: 0.418, acc5: 0.706, ep: 2\
Testing loss: 28.595, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.297, acc1: 0.669, acc5: 0.854\
Training loss: 2.272, acc1: 0.429, acc5: 0.725, ep: 3\
\
Validation loss: 2.277, acc1: 0.431, acc5: 0.739, ep: 3\
Testing loss: 30.019, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.270, acc1: 0.646, acc5: 0.862\
Training loss: 2.149, acc1: 0.452, acc5: 0.752, ep: 4\
\
Validation loss: 2.212, acc1: 0.442, acc5: 0.739, ep: 4\
Testing loss: 28.685, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.199, acc1: 0.701, acc5: 0.886\
Training loss: 2.079, acc1: 0.466, acc5: 0.762, ep: 5\
\
Validation loss: 2.148, acc1: 0.444, acc5: 0.757, ep: 5\
Testing loss: 28.626, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.175, acc1: 0.709, acc5: 0.870\
Training loss: 1.947, acc1: 0.489, acc5: 0.792, ep: 6\
\
Validation loss: 2.109, acc1: 0.455, acc5: 0.766, ep: 6\
Testing loss: 26.037, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 1.114, acc1: 0.677, acc5: 0.874\
Training loss: 1.878, acc1: 0.496, acc5: 0.794, ep: 7\
\
Validation loss: 2.077, acc1: 0.460, acc5: 0.770, ep: 7\
Testing loss: 27.002, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 0.998, acc1: 0.732, acc5: 0.917\
Training loss: 1.758, acc1: 0.522, acc5: 0.822, ep: 8\
\
Validation loss: 2.014, acc1: 0.476, acc5: 0.783, ep: 8\
Testing loss: 24.796, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 0.897, acc1: 0.724, acc5: 0.945\
Training loss: 1.700, acc1: 0.523, acc5: 0.831, ep: 9\
\
Validation loss: 2.036, acc1: 0.480, acc5: 0.775, ep: 9\
Testing loss: 26.101, acc1: 0.000, acc5: 0.004\
\
Percent: [####################] 100.00% Finished. tr loss: 0.903, acc1: 0.748, acc5: 0.913\
Training loss: 1.595, acc1: 0.554, acc5: 0.845, ep: 10\
\
Validation loss: 2.005, acc1: 0.489, acc5: 0.789, ep: 10\
Testing loss: 28.123, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 0.811, acc1: 0.791, acc5: 0.953\
Training loss: 1.520, acc1: 0.577, acc5: 0.868, ep: 11\
\
Validation loss: 2.066, acc1: 0.494, acc5: 0.783, ep: 11\
Testing loss: 26.782, acc1: 0.000, acc5: 0.006\
\
Percent: [####################] 100.00% Finished. tr loss: 0.785, acc1: 0.748, acc5: 0.937\
Training loss: 1.421, acc1: 0.592, acc5: 0.877, ep: 12\
\
Validation loss: 2.046, acc1: 0.485, acc5: 0.783, ep: 12\
Testing loss: 27.512, acc1: 0.000, acc5: 0.006\
\
Percent: [####################] 100.00% Finished. tr loss: 0.779, acc1: 0.776, acc5: 0.945\
Training loss: 1.361, acc1: 0.609, acc5: 0.889, ep: 13\
\
Validation loss: 2.036, acc1: 0.498, acc5: 0.794, ep: 13\
Testing loss: 26.816, acc1: 0.000, acc5: 0.004\
\
Percent: [####################] 100.00% Finished. tr loss: 0.739, acc1: 0.768, acc5: 0.953\
Training loss: 1.292, acc1: 0.624, acc5: 0.902, ep: 14\
\
Validation loss: 2.088, acc1: 0.494, acc5: 0.792, ep: 14\
Testing loss: 28.086, acc1: 0.000, acc5: 0.014\
\
Percent: [####################] 100.00% Finished. tr loss: 0.622, acc1: 0.819, acc5: 0.961\
Training loss: 1.182, acc1: 0.647, acc5: 0.916, ep: 15\
\
Validation loss: 2.107, acc1: 0.483, acc5: 0.791, ep: 15\
Testing loss: 29.700, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 0.613, acc1: 0.811, acc5: 0.965\
Training loss: 1.119, acc1: 0.657, acc5: 0.922, ep: 16\
\
Validation loss: 2.090, acc1: 0.497, acc5: 0.794, ep: 16\
Testing loss: 27.635, acc1: 0.000, acc5: 0.006\
\
Percent: [####################] 100.00% Finished. tr loss: 0.582, acc1: 0.815, acc5: 0.972\
Training loss: 1.067, acc1: 0.676, acc5: 0.932, ep: 17\
\
Validation loss: 2.165, acc1: 0.487, acc5: 0.793, ep: 17\
Testing loss: 29.840, acc1: 0.000, acc5: 0.006\
\
Percent: [####################] 100.00% Finished. tr loss: 0.582, acc1: 0.823, acc5: 0.972\
Training loss: 1.047, acc1: 0.676, acc5: 0.939, ep: 18\
\
Validation loss: 2.205, acc1: 0.495, acc5: 0.794, ep: 18\
Testing loss: 28.172, acc1: 0.000, acc5: 0.006\
\
Early stopping applied\
\
Testing loss: 28.172, acc1: 0.000, acc5: 0.006\
ensemble_embedding Parameter sets: [200, 200, 0.01, 0.5, 1, 0.5, 30, 100, 130]\
## Building an RNN model\
Tensor("Unigram/Unigram/embedding_lookup:0", shape=(?, 60, 30), dtype=float32)\
Tensor("Bigram/Bigram/embedding_lookup:0", shape=(?, 60, 100), dtype=float32)\
Tensor("Trigram/Trigram/embedding_lookup:0", shape=(?, 60, 130), dtype=float32)\
model variables ['Unigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0', 'Unigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0', 'Bigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0', 'Bigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0', 'Trigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0', 'Trigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0', 'Hidden1/Weights:0', 'Hidden1/Biases:0', 'Output/Weights:0', 'Output/Biases:0']\
## Training\
Percent: [####################] 100.00% Finished. tr loss: 16.722, acc1: 0.098, acc5: 0.287\
Training loss: 8.001, acc1: 0.168, acc5: 0.363, ep: 0\
\
Validation loss: 2.905, acc1: 0.310, acc5: 0.634, ep: 0\
Testing loss: 14.610, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 1.758, acc1: 0.571, acc5: 0.748\
Training loss: 2.947, acc1: 0.325, acc5: 0.595, ep: 1\
\
Validation loss: 2.650, acc1: 0.350, acc5: 0.655, ep: 1\
Testing loss: 26.216, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.479, acc1: 0.606, acc5: 0.799\
Training loss: 2.613, acc1: 0.362, acc5: 0.644, ep: 2\
\
Validation loss: 2.532, acc1: 0.374, acc5: 0.684, ep: 2\
Testing loss: 24.688, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.410, acc1: 0.626, acc5: 0.835\
Training loss: 2.466, acc1: 0.390, acc5: 0.675, ep: 3\
\
Validation loss: 2.462, acc1: 0.389, acc5: 0.689, ep: 3\
Testing loss: 24.676, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.329, acc1: 0.650, acc5: 0.835\
Training loss: 2.325, acc1: 0.417, acc5: 0.703, ep: 4\
\
Validation loss: 2.416, acc1: 0.409, acc5: 0.689, ep: 4\
Testing loss: 23.704, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.354, acc1: 0.634, acc5: 0.854\
Training loss: 2.238, acc1: 0.426, acc5: 0.733, ep: 5\
\
Validation loss: 2.371, acc1: 0.412, acc5: 0.708, ep: 5\
Testing loss: 21.973, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.220, acc1: 0.673, acc5: 0.909\
Training loss: 2.126, acc1: 0.442, acc5: 0.753, ep: 6\
\
Validation loss: 2.330, acc1: 0.420, acc5: 0.716, ep: 6\
Testing loss: 22.137, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.139, acc1: 0.705, acc5: 0.882\
Training loss: 2.012, acc1: 0.472, acc5: 0.769, ep: 7\
\
Validation loss: 2.298, acc1: 0.425, acc5: 0.742, ep: 7\
Testing loss: 22.573, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.117, acc1: 0.681, acc5: 0.870\
Training loss: 1.945, acc1: 0.485, acc5: 0.784, ep: 8\
\
Validation loss: 2.252, acc1: 0.439, acc5: 0.750, ep: 8\
Testing loss: 23.106, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.100, acc1: 0.713, acc5: 0.882\
Training loss: 1.848, acc1: 0.505, acc5: 0.806, ep: 9\
\
Validation loss: 2.244, acc1: 0.434, acc5: 0.756, ep: 9\
Testing loss: 23.192, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 0.969, acc1: 0.736, acc5: 0.917\
Training loss: 1.746, acc1: 0.524, acc5: 0.822, ep: 10\
\
Validation loss: 2.256, acc1: 0.439, acc5: 0.750, ep: 10\
Testing loss: 24.149, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 1.008, acc1: 0.709, acc5: 0.890\
Training loss: 1.676, acc1: 0.531, acc5: 0.835, ep: 11\
\
Validation loss: 2.243, acc1: 0.447, acc5: 0.755, ep: 11\
Testing loss: 24.577, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 0.939, acc1: 0.732, acc5: 0.933\
Training loss: 1.609, acc1: 0.547, acc5: 0.852, ep: 12\
\
Validation loss: 2.253, acc1: 0.437, acc5: 0.753, ep: 12\
Testing loss: 24.076, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 0.926, acc1: 0.720, acc5: 0.913\
Training loss: 1.540, acc1: 0.558, acc5: 0.858, ep: 13\
\
Validation loss: 2.284, acc1: 0.464, acc5: 0.762, ep: 13\
Testing loss: 24.124, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 0.876, acc1: 0.756, acc5: 0.941\
Training loss: 1.468, acc1: 0.589, acc5: 0.868, ep: 14\
\
Validation loss: 2.232, acc1: 0.462, acc5: 0.769, ep: 14\
Testing loss: 26.622, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 0.838, acc1: 0.787, acc5: 0.937\
Training loss: 1.436, acc1: 0.591, acc5: 0.878, ep: 15\
\
Validation loss: 2.321, acc1: 0.458, acc5: 0.759, ep: 15\
Testing loss: 26.753, acc1: 0.000, acc5: 0.004\
\
Percent: [####################] 100.00% Finished. tr loss: 0.722, acc1: 0.780, acc5: 0.945\
Training loss: 1.341, acc1: 0.612, acc5: 0.890, ep: 16\
\
Validation loss: 2.349, acc1: 0.452, acc5: 0.775, ep: 16\
Testing loss: 28.874, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 0.713, acc1: 0.760, acc5: 0.961\
Training loss: 1.313, acc1: 0.617, acc5: 0.900, ep: 17\
\
Validation loss: 2.368, acc1: 0.470, acc5: 0.780, ep: 17\
Testing loss: 25.802, acc1: 0.001, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 0.712, acc1: 0.776, acc5: 0.953\
Training loss: 1.184, acc1: 0.643, acc5: 0.918, ep: 18\
\
Validation loss: 2.351, acc1: 0.456, acc5: 0.778, ep: 18\
Testing loss: 26.180, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 0.597, acc1: 0.823, acc5: 0.972\
Training loss: 1.127, acc1: 0.671, acc5: 0.918, ep: 19\
\
Validation loss: 2.378, acc1: 0.470, acc5: 0.782, ep: 19\
Testing loss: 27.294, acc1: 0.000, acc5: 0.002\
\
Percent: [####################] 100.00% Finished. tr loss: 0.638, acc1: 0.807, acc5: 0.965\
Training loss: 1.112, acc1: 0.659, acc5: 0.926, ep: 20\
\
Validation loss: 2.434, acc1: 0.471, acc5: 0.770, ep: 20\
Testing loss: 26.925, acc1: 0.000, acc5: 0.002\
\
Percent: [####################] 100.00% Finished. tr loss: 0.674, acc1: 0.811, acc5: 0.949\
Training loss: 1.091, acc1: 0.671, acc5: 0.929, ep: 21\
\
Validation loss: 2.474, acc1: 0.458, acc5: 0.774, ep: 21\
Testing loss: 27.909, acc1: 0.000, acc5: 0.003\
\
Percent: [####################] 100.00% Finished. tr loss: 0.570, acc1: 0.827, acc5: 0.972\
Training loss: 1.014, acc1: 0.695, acc5: 0.937, ep: 22\
\
Validation loss: 2.566, acc1: 0.462, acc5: 0.761, ep: 22\
Testing loss: 26.622, acc1: 0.000, acc5: 0.004\
\
Percent: [####################] 100.00% Finished. tr loss: 0.481, acc1: 0.839, acc5: 0.976\
Training loss: 0.923, acc1: 0.718, acc5: 0.952, ep: 23\
\
Validation loss: 2.642, acc1: 0.457, acc5: 0.767, ep: 23\
Testing loss: 26.280, acc1: 0.000, acc5: 0.010\
\
Percent: [####################] 100.00% Finished. tr loss: 0.624, acc1: 0.815, acc5: 0.969\
Training loss: 0.966, acc1: 0.695, acc5: 0.945, ep: 24\
\
Validation loss: 2.702, acc1: 0.455, acc5: 0.750, ep: 24\
Testing loss: 26.870, acc1: 0.001, acc5: 0.008\
\
Percent: [####################] 100.00% Finished. tr loss: 0.495, acc1: 0.846, acc5: 0.980\
Training loss: 0.879, acc1: 0.720, acc5: 0.954, ep: 25\
\
Validation loss: 2.746, acc1: 0.453, acc5: 0.752, ep: 25\
Testing loss: 28.556, acc1: 0.000, acc5: 0.003\
\
Early stopping applied\
\
Testing loss: 28.556, acc1: 0.000, acc5: 0.003\
ensemble_embedding Parameter sets: [200, 200, 0.01, 0.5, 1, 0.5, 30, 100, 130]\
## Building an RNN model\
Tensor("Unigram/Unigram/embedding_lookup:0", shape=(?, 60, 30), dtype=float32)\
Tensor("Bigram/Bigram/embedding_lookup:0", shape=(?, 60, 100), dtype=float32)\
Tensor("Trigram/Trigram/embedding_lookup:0", shape=(?, 60, 130), dtype=float32)\
model variables ['Unigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0', 'Unigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0', 'Bigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0', 'Bigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0', 'Trigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0', 'Trigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0', 'Hidden1/Weights:0', 'Hidden1/Biases:0', 'Output/Weights:0', 'Output/Biases:0']\
## Training\
Percent: [####################] 100.00% Finished. tr loss: 14.318, acc1: 0.118, acc5: 0.291\
Training loss: 7.758, acc1: 0.179, acc5: 0.369, ep: 0\
\
Validation loss: 2.877, acc1: 0.303, acc5: 0.611, ep: 0\
Testing loss: 16.435, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.600, acc1: 0.591, acc5: 0.819\
Training loss: 2.954, acc1: 0.312, acc5: 0.604, ep: 1\
\
Validation loss: 2.619, acc1: 0.355, acc5: 0.678, ep: 1\
Testing loss: 23.621, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.471, acc1: 0.622, acc5: 0.815\
Training loss: 2.598, acc1: 0.374, acc5: 0.651, ep: 2\
\
Validation loss: 2.502, acc1: 0.389, acc5: 0.676, ep: 2\
Testing loss: 25.168, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.363, acc1: 0.626, acc5: 0.878\
Training loss: 2.413, acc1: 0.405, acc5: 0.693, ep: 3\
\
Validation loss: 2.447, acc1: 0.397, acc5: 0.690, ep: 3\
Testing loss: 24.021, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.323, acc1: 0.650, acc5: 0.854\
Training loss: 2.268, acc1: 0.426, acc5: 0.714, ep: 4\
\
Validation loss: 2.378, acc1: 0.408, acc5: 0.712, ep: 4\
Testing loss: 24.769, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.263, acc1: 0.654, acc5: 0.874\
Training loss: 2.159, acc1: 0.444, acc5: 0.750, ep: 5\
\
Validation loss: 2.351, acc1: 0.407, acc5: 0.715, ep: 5\
Testing loss: 24.105, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.189, acc1: 0.685, acc5: 0.874\
Training loss: 2.056, acc1: 0.480, acc5: 0.760, ep: 6\
\
Validation loss: 2.311, acc1: 0.418, acc5: 0.727, ep: 6\
Testing loss: 24.762, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.203, acc1: 0.669, acc5: 0.878\
Training loss: 2.015, acc1: 0.473, acc5: 0.781, ep: 7\
\
Validation loss: 2.268, acc1: 0.427, acc5: 0.739, ep: 7\
Testing loss: 27.587, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.162, acc1: 0.677, acc5: 0.878\
Training loss: 1.896, acc1: 0.495, acc5: 0.794, ep: 8\
\
Validation loss: 2.243, acc1: 0.454, acc5: 0.742, ep: 8\
Testing loss: 24.964, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 1.043, acc1: 0.697, acc5: 0.906\
Training loss: 1.804, acc1: 0.506, acc5: 0.811, ep: 9\
\
Validation loss: 2.256, acc1: 0.449, acc5: 0.751, ep: 9\
Testing loss: 25.220, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 1.029, acc1: 0.701, acc5: 0.909\
Training loss: 1.726, acc1: 0.533, acc5: 0.823, ep: 10\
\
Validation loss: 2.271, acc1: 0.440, acc5: 0.766, ep: 10\
Testing loss: 25.980, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 1.008, acc1: 0.697, acc5: 0.917\
Training loss: 1.614, acc1: 0.527, acc5: 0.852, ep: 11\
\
Validation loss: 2.248, acc1: 0.466, acc5: 0.766, ep: 11\
Testing loss: 26.733, acc1: 0.000, acc5: 0.003\
\
Percent: [####################] 100.00% Finished. tr loss: 0.907, acc1: 0.728, acc5: 0.929\
Training loss: 1.554, acc1: 0.553, acc5: 0.865, ep: 12\
\
Validation loss: 2.331, acc1: 0.457, acc5: 0.761, ep: 12\
Testing loss: 29.645, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 0.860, acc1: 0.744, acc5: 0.925\
Training loss: 1.498, acc1: 0.561, acc5: 0.859, ep: 13\
\
Validation loss: 2.319, acc1: 0.455, acc5: 0.762, ep: 13\
Testing loss: 26.078, acc1: 0.000, acc5: 0.003\
\
Percent: [####################] 100.00% Finished. tr loss: 0.788, acc1: 0.756, acc5: 0.945\
Training loss: 1.392, acc1: 0.592, acc5: 0.882, ep: 14\
\
Validation loss: 2.369, acc1: 0.451, acc5: 0.761, ep: 14\
Testing loss: 27.864, acc1: 0.000, acc5: 0.002\
\
Percent: [####################] 100.00% Finished. tr loss: 0.799, acc1: 0.764, acc5: 0.945\
Training loss: 1.322, acc1: 0.600, acc5: 0.893, ep: 15\
\
Validation loss: 2.383, acc1: 0.448, acc5: 0.778, ep: 15\
Testing loss: 28.590, acc1: 0.000, acc5: 0.002\
\
Percent: [####################] 100.00% Finished. tr loss: 0.706, acc1: 0.776, acc5: 0.957\
Training loss: 1.276, acc1: 0.625, acc5: 0.900, ep: 16\
\
Validation loss: 2.405, acc1: 0.464, acc5: 0.774, ep: 16\
Testing loss: 27.551, acc1: 0.000, acc5: 0.001\
\
Early stopping applied\
\
Testing loss: 27.551, acc1: 0.000, acc5: 0.001\
ensemble_embedding Parameter sets: [200, 200, 0.01, 0.5, 1, 0.5, 30, 100, 130]\
## Building an RNN model\
Tensor("Unigram/Unigram/embedding_lookup:0", shape=(?, 60, 30), dtype=float32)\
Tensor("Bigram/Bigram/embedding_lookup:0", shape=(?, 60, 100), dtype=float32)\
Tensor("Trigram/Trigram/embedding_lookup:0", shape=(?, 60, 130), dtype=float32)\
model variables ['Unigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0', 'Unigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0', 'Bigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0', 'Bigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0', 'Trigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/weights:0', 'Trigram/RNN/multi_rnn_cell/cell_0/basic_lstm_cell/biases:0', 'Hidden1/Weights:0', 'Hidden1/Biases:0', 'Output/Weights:0', 'Output/Biases:0']\
## Training\
Percent: [####################] 100.00% Finished. tr loss: 17.097, acc1: 0.102, acc5: 0.291\
Training loss: 7.730, acc1: 0.172, acc5: 0.374, ep: 0\
\
Validation loss: 2.849, acc1: 0.318, acc5: 0.649, ep: 0\
Testing loss: 12.802, acc1: 0.000, acc5: 0.019\
\
Percent: [####################] 100.00% Finished. tr loss: 1.631, acc1: 0.583, acc5: 0.791\
Training loss: 2.902, acc1: 0.330, acc5: 0.608, ep: 1\
\
Validation loss: 2.624, acc1: 0.350, acc5: 0.660, ep: 1\
Testing loss: 24.958, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 1.438, acc1: 0.622, acc5: 0.831\
Training loss: 2.560, acc1: 0.372, acc5: 0.663, ep: 2\
\
Validation loss: 2.503, acc1: 0.378, acc5: 0.688, ep: 2\
Testing loss: 25.381, acc1: 0.000, acc5: 0.001\
\
Percent: [####################] 100.00% Finished. tr loss: 1.412, acc1: 0.638, acc5: 0.827\
Training loss: 2.412, acc1: 0.395, acc5: 0.683, ep: 3\
\
Validation loss: 2.424, acc1: 0.405, acc5: 0.692, ep: 3\
Testing loss: 26.422, acc1: 0.000, acc5: 0.000\
\
Percent: [####################] 100.00% Finished. tr loss: 1.364, acc1: 0.650, acc5: 0.850\
Training loss: 2.242, acc1: 0.430, acc5: 0.723, ep: 4\
\
Validation loss: 2.369, acc1: 0.413, acc5: 0.710, ep: 4\
Testing loss: 25.844, acc1: 0.000, acc5: 0.003\
\
Percent: [#                   ] 2.79%  tr loss: 2.235, acc1: 0.397, acc5: 0.740}